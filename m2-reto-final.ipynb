{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install imutils","metadata":{"papermill":{"duration":10.967732,"end_time":"2022-04-05T17:27:14.357104","exception":false,"start_time":"2022-04-05T17:27:03.389372","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:38:59.893291Z","iopub.execute_input":"2022-06-26T06:38:59.894373Z","iopub.status.idle":"2022-06-26T06:39:13.441121Z","shell.execute_reply.started":"2022-06-26T06:38:59.894229Z","shell.execute_reply":"2022-06-26T06:39:13.439908Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nfrom tqdm import tqdm\nimport cv2\nimport os\nimport shutil\nimport itertools\nimport imutils\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.xception import preprocess_input , Xception\nfrom tensorflow.keras.applications.resnet import ResNet50\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom keras.optimizers import gradient_descent_v2  \n\n\nfrom tensorflow.keras.callbacks import EarlyStopping\ninit_notebook_mode(connected=True)\nRANDOM_SEED = 123\nprint(\"ok\")","metadata":{"papermill":{"duration":7.713063,"end_time":"2022-04-05T17:27:22.094558","exception":false,"start_time":"2022-04-05T17:27:14.381495","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:13.443485Z","iopub.execute_input":"2022-06-26T06:39:13.444081Z","iopub.status.idle":"2022-06-26T06:39:19.221570Z","shell.execute_reply.started":"2022-06-26T06:39:13.444039Z","shell.execute_reply":"2022-06-26T06:39:19.220545Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"modelChoiceTxtInput = ''\nIMG_SIZE = (224,224)\n\nwhile modelChoiceTxtInput not in (\"VGG16\", \"Xception\", \"ResNet50\"):\n    modelChoiceTxt = \"Escriba el modelo a usar. Las opciones son VGG16, Xception o ResNet50\"\n    modelChoiceTxt +=\"\\nEscriba:  \"\n\n    modelChoiceTxtInput= input(modelChoiceTxt)\n    print(f\"\\nHas seleccionado {modelChoiceTxtInput}\")\n\n\n\nif modelChoiceTxtInput == \"VGG16\":\n    base_model = VGG16(weights=\"imagenet\",include_top=False,input_shape=IMG_SIZE + (3,))\nelse:\n    if modelChoiceTxtInput == \"Xception\":\n        base_model = Xception(\n        include_top=False,\n        weights=\"imagenet\",\n        classes=2,\n        classifier_activation=\"softmax\", \n        input_shape=IMG_SIZE + (3,))\n    else:\n        if modelChoiceTxtInput == \"ResNet50\":\n            base_model = ResNet50(\n            include_top=False,\n            weights=\"imagenet\",\n            classes=2,\n            input_shape=IMG_SIZE + (3,))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T06:39:19.223134Z","iopub.execute_input":"2022-06-26T06:39:19.223770Z","iopub.status.idle":"2022-06-26T06:39:29.714740Z","shell.execute_reply.started":"2022-06-26T06:39:19.223733Z","shell.execute_reply":"2022-06-26T06:39:29.713719Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!apt-get install tree\n#clear_output()\n# Creamos las carpetas que contendrán las imagenes de entrenamiento\n!mkdir TRAIN TEST VAL TRAIN/YES TRAIN/NO TEST/YES TEST/NO VAL/YES VAL/NO\n!tree -d","metadata":{"papermill":{"duration":4.317215,"end_time":"2022-04-05T17:27:26.434325","exception":false,"start_time":"2022-04-05T17:27:22.11711","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:29.717128Z","iopub.execute_input":"2022-06-26T06:39:29.717481Z","iopub.status.idle":"2022-06-26T06:39:33.328742Z","shell.execute_reply.started":"2022-06-26T06:39:29.717444Z","shell.execute_reply":"2022-06-26T06:39:33.327612Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"IMG_PATH = '../input/brain-mri-images-for-brain-tumor-detection/'\n# Divide las imagenes del dataset original en train/val/test\nfor CLASS in os.listdir(IMG_PATH):\n   #if os.path.isdir(CLASS):\n    if (os.path.isfile(CLASS)==False) and (CLASS==\"yes\" or CLASS==\"no\"):\n        print(CLASS)\n        IMG_NUM = len(os.listdir(IMG_PATH + CLASS))\n        print(IMG_NUM)\n        for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH + CLASS)):\n            img = IMG_PATH + CLASS + '/' + FILE_NAME\n            print(img)\n            if n < 25:\n                shutil.copy(img, 'TEST/' + CLASS.upper() + '/' + FILE_NAME)\n                print(\"TO TEST\")\n            elif n < 0.8*IMG_NUM:\n                shutil.copy(img, 'TRAIN/'+ CLASS.upper() + '/' + FILE_NAME)\n                print(\"TO TRAIN\")\n            else:\n                shutil.copy(img, 'VAL/'+ CLASS.upper() + '/' + FILE_NAME)\n                print(\"TO VAL\")\n","metadata":{"papermill":{"duration":1.618452,"end_time":"2022-04-05T17:27:28.079946","exception":false,"start_time":"2022-04-05T17:27:26.461494","status":"completed"},"tags":[],"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-26T06:39:33.331513Z","iopub.execute_input":"2022-06-26T06:39:33.331929Z","iopub.status.idle":"2022-06-26T06:39:34.789035Z","shell.execute_reply.started":"2022-06-26T06:39:33.331882Z","shell.execute_reply":"2022-06-26T06:39:34.788013Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def load_data(dir_path, img_size=(100,100)):\n    #Carga las imagebes como np.arrays y les cambia el tamaño\n    X = []\n    y = []\n    i = 0\n    labels = dict()\n    for path in tqdm(sorted(os.listdir(dir_path))):\n        if not path.startswith('.'):\n            labels[i] = path\n            for file in os.listdir(dir_path + path):\n                if not file.startswith('.'):\n                    img = cv2.imread(dir_path + path + '/' + file)\n                    X.append(img)\n                    y.append(i)\n            i += 1\n    X = np.array(X,dtype=object)\n    y = np.array(y)\n    print(f'{len(X)} imagenes cargadas desde: {dir_path}.')\n    return X, y, labels\n\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    Esta funcion imprime y plotea la matriz de confucion.\n    Se puede aplicar Normalization haciendo `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","metadata":{"papermill":{"duration":0.048033,"end_time":"2022-04-05T17:27:28.160642","exception":false,"start_time":"2022-04-05T17:27:28.112609","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:34.790448Z","iopub.execute_input":"2022-06-26T06:39:34.790991Z","iopub.status.idle":"2022-06-26T06:39:34.806978Z","shell.execute_reply.started":"2022-06-26T06:39:34.790954Z","shell.execute_reply":"2022-06-26T06:39:34.806011Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = 'TRAIN/'\nTEST_DIR = 'TEST/'\nVAL_DIR = 'VAL/'\nIMG_SIZE = (224,224)\n\n# Cargamos cada uno de los conjuntos de imagener entrenamiento\n# prueba y validación\nX_train, y_train, labels = load_data(TRAIN_DIR, IMG_SIZE)\nprint(labels)\nX_test, y_test, _ = load_data(TEST_DIR, IMG_SIZE)\nX_val, y_val, _ = load_data(VAL_DIR, IMG_SIZE)","metadata":{"papermill":{"duration":0.77709,"end_time":"2022-04-05T17:27:28.969519","exception":false,"start_time":"2022-04-05T17:27:28.192429","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:34.809155Z","iopub.execute_input":"2022-06-26T06:39:34.809722Z","iopub.status.idle":"2022-06-26T06:39:35.389710Z","shell.execute_reply.started":"2022-06-26T06:39:34.809684Z","shell.execute_reply":"2022-06-26T06:39:35.388655Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def plot_samples(X, y, labels_dict, n=50):\n    \"\"\"\n    Crea un gridplot para mostrar un número deseado de imágenes  \n    \"\"\"\n    for index in range(len(labels_dict)):\n        imgs = X[np.argwhere(y == index)][:n]\n        j = 10\n        i = int(n/j)\n\n        plt.figure(figsize=(15,6))\n        c = 1\n        for img in imgs:\n            plt.subplot(i,j,c)\n            plt.imshow(img[0])\n\n            plt.xticks([])\n            plt.yticks([])\n            c += 1\n        plt.suptitle('Tumor: {}'.format(labels_dict[index]))\n        plt.show()","metadata":{"papermill":{"duration":0.046253,"end_time":"2022-04-05T17:27:29.055793","exception":false,"start_time":"2022-04-05T17:27:29.00954","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:35.391178Z","iopub.execute_input":"2022-06-26T06:39:35.391650Z","iopub.status.idle":"2022-06-26T06:39:35.401365Z","shell.execute_reply.started":"2022-06-26T06:39:35.391611Z","shell.execute_reply":"2022-06-26T06:39:35.400234Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"plot_samples(X_train, y_train, labels, 30)","metadata":{"papermill":{"duration":3.41737,"end_time":"2022-04-05T17:27:32.509899","exception":false,"start_time":"2022-04-05T17:27:29.092529","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:35.402884Z","iopub.execute_input":"2022-06-26T06:39:35.403224Z","iopub.status.idle":"2022-06-26T06:39:38.840975Z","shell.execute_reply.started":"2022-06-26T06:39:35.403187Z","shell.execute_reply":"2022-06-26T06:39:38.840103Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Homomorphic filter class\nclass HomomorphicFilter:\n    \"\"\"Homomorphic filter implemented with diferents filters and an option to an external filter.\n    \n    High-frequency filters implemented:\n        butterworth\n        gaussian\n    Attributes:\n        a, b: Floats used on emphasis filter:\n            H = a + b*H\n     \n       .\n    \"\"\"\n\n    def __init__(self, a = 0.5, b = 1.5):\n        self.a = float(a)\n        self.b = float(b)\n\n    # Filters\n    def __butterworth_filter(self, I_shape, filter_params):\n        P = I_shape[0]/2\n        Q = I_shape[1]/2\n        U, V = np.meshgrid(range(I_shape[0]), range(I_shape[1]), sparse=False, indexing='ij')\n        Duv = (((U-P)**2+(V-Q)**2)).astype(float)\n        H = 1/(1+(Duv/filter_params[0]**2)**filter_params[1])\n        return (1 - H)\n\n    def __gaussian_filter(self, I_shape, filter_params):\n        P = I_shape[0]/2\n        Q = I_shape[1]/2\n        H = np.zeros(I_shape)\n        U, V = np.meshgrid(range(I_shape[0]), range(I_shape[1]), sparse=False, indexing='ij')\n        Duv = (((U-P)**2+(V-Q)**2)).astype(float)\n        H = np.exp((-Duv/(2*(filter_params[0])**2)))\n        return (1 - H)\n\n    # Methods\n    def __apply_filter(self, I, H):\n        H = np.fft.fftshift(H)\n        I_filtered = (self.a + self.b*H)*I\n        return I_filtered\n\n    def filter(self, I, filter_params, filter='butterworth', H = None):\n        \"\"\"\n        Method to apply homormophic filter on an image\n        Attributes:\n            I: Single channel image\n            filter_params: Parameters to be used on filters:\n                butterworth:\n                    filter_params[0]: Cutoff frequency \n                    filter_params[1]: Order of filter\n                gaussian:\n                    filter_params[0]: Cutoff frequency\n            filter: Choose of the filter, options:\n                butterworth\n                gaussian\n                external\n            H: Used to pass external filter\n        \"\"\"\n\n        #  Validating image\n        if len(I.shape) is not 2:\n            raise Exception('Improper image')\n\n        # Take the image to log domain and then to frequency domain \n        I_log = np.log1p(np.array(I, dtype=\"float\"))\n        I_fft = np.fft.fft2(I_log)\n\n        # Filters\n        if filter=='butterworth':\n            H = self.__butterworth_filter(I_shape = I_fft.shape, filter_params = filter_params)\n        elif filter=='gaussian':\n            H = self.__gaussian_filter(I_shape = I_fft.shape, filter_params = filter_params)\n        elif filter=='external':\n            print('external')\n            if len(H.shape) is not 2:\n                raise Exception('Invalid external filter')\n        else:\n            raise Exception('Selected filter not implemented')\n        \n        # Apply filter on frequency domain then take the image back to spatial domain\n        I_fft_filt = self.__apply_filter(I = I_fft, H = H)\n        I_filt = np.fft.ifft2(I_fft_filt)\n        I = np.exp(np.real(I_filt))-1\n        return np.uint8(I)\n# End of class HomomorphicFilter","metadata":{"papermill":{"duration":0.070938,"end_time":"2022-04-05T17:27:32.634201","exception":false,"start_time":"2022-04-05T17:27:32.563263","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:38.845398Z","iopub.execute_input":"2022-06-26T06:39:38.845958Z","iopub.status.idle":"2022-06-26T06:39:38.865874Z","shell.execute_reply.started":"2022-06-26T06:39:38.845921Z","shell.execute_reply":"2022-06-26T06:39:38.863124Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def crop_imgs(set_name, add_pixels_value=0):\n    \"\"\"\n    Encuentra los puntos extremos de la imagen y la corta de forma rectangular\n    \"\"\"\n    set_new = []\n    for img in set_name:\n        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n        # threshold the image, then perform a series of erosions +\n        # dilations to remove any small regions of noise\n        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n        thresh = cv2.erode(thresh, None, iterations=2)\n        thresh = cv2.dilate(thresh, None, iterations=2)\n\n        # find contours in thresholded image, then grab the largest one\n        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        cnts = imutils.grab_contours(cnts)\n        c = max(cnts, key=cv2.contourArea)\n\n        # find the extreme points\n        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n        extRight = tuple(c[c[:, :, 0].argmax()][0])\n        extTop = tuple(c[c[:, :, 1].argmin()][0])\n        extBot = tuple(c[c[:, :, 1].argmax()][0])\n\n        ADD_PIXELS = add_pixels_value\n        new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n        new_img = cv2.cvtColor(new_img, cv2.COLOR_RGB2GRAY)\n        homo_filter = HomomorphicFilter(a = 0.9, b = 1.4)\n        new_img = homo_filter.filter(I=new_img, filter_params=[30,2])\n        new_img = cv2.equalizeHist(new_img)\n        new_img = cv2.cvtColor(new_img,cv2.COLOR_GRAY2RGB)\n        set_new.append(new_img)\n\n    return np.array(set_new, dtype=object)","metadata":{"papermill":{"duration":0.067748,"end_time":"2022-04-05T17:27:32.753163","exception":false,"start_time":"2022-04-05T17:27:32.685415","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:38.868849Z","iopub.execute_input":"2022-06-26T06:39:38.869707Z","iopub.status.idle":"2022-06-26T06:39:39.035198Z","shell.execute_reply.started":"2022-06-26T06:39:38.869671Z","shell.execute_reply":"2022-06-26T06:39:39.033722Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Aplicamos a cada uno de los subconjuntos\nX_train_crop = crop_imgs(set_name=X_train)\nX_val_crop = crop_imgs(set_name=X_val)\nX_test_crop = crop_imgs(set_name=X_test)","metadata":{"papermill":{"duration":6.688687,"end_time":"2022-04-05T17:27:39.49273","exception":false,"start_time":"2022-04-05T17:27:32.804043","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:39.037391Z","iopub.execute_input":"2022-06-26T06:39:39.039205Z","iopub.status.idle":"2022-06-26T06:39:44.319347Z","shell.execute_reply.started":"2022-06-26T06:39:39.039173Z","shell.execute_reply":"2022-06-26T06:39:44.318368Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plot_samples(X_train_crop, y_train, labels, 30)","metadata":{"papermill":{"duration":3.061963,"end_time":"2022-04-05T17:27:42.608762","exception":false,"start_time":"2022-04-05T17:27:39.546799","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:44.320926Z","iopub.execute_input":"2022-06-26T06:39:44.321307Z","iopub.status.idle":"2022-06-26T06:39:47.094267Z","shell.execute_reply.started":"2022-06-26T06:39:44.321270Z","shell.execute_reply":"2022-06-26T06:39:47.093304Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def save_new_images(x_set, y_set, folder_name):\n    i = 0\n    for (img, imclass) in zip(x_set, y_set):\n        if imclass == 0:\n            cv2.imwrite(folder_name+'NO/'+str(i)+'.jpg', img)\n        else:\n            cv2.imwrite(folder_name+'YES/'+str(i)+'.jpg', img)\n        i += 1","metadata":{"papermill":{"duration":0.086122,"end_time":"2022-04-05T17:27:42.772242","exception":false,"start_time":"2022-04-05T17:27:42.68612","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:47.095893Z","iopub.execute_input":"2022-06-26T06:39:47.096760Z","iopub.status.idle":"2022-06-26T06:39:47.103441Z","shell.execute_reply.started":"2022-06-26T06:39:47.096722Z","shell.execute_reply":"2022-06-26T06:39:47.102607Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Creamos las carpetas donde guardaremos las imagenes\n!mkdir TRAIN_CROP TEST_CROP VAL_CROP TRAIN_CROP/YES \n!mkdir TRAIN_CROP/NO TEST_CROP/YES TEST_CROP/NO VAL_CROP/YES \n!mkdir VAL_CROP/NO\n# Guardamos las imagenes que recortamos en las carpetas anteriores\nsave_new_images(X_train_crop, y_train, folder_name='TRAIN_CROP/')\nsave_new_images(X_val_crop, y_val, folder_name='VAL_CROP/')\nsave_new_images(X_test_crop, y_test, folder_name='TEST_CROP/')","metadata":{"papermill":{"duration":3.19626,"end_time":"2022-04-05T17:27:46.046046","exception":false,"start_time":"2022-04-05T17:27:42.849786","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:47.104734Z","iopub.execute_input":"2022-06-26T06:39:47.105535Z","iopub.status.idle":"2022-06-26T06:39:49.940138Z","shell.execute_reply.started":"2022-06-26T06:39:47.105500Z","shell.execute_reply":"2022-06-26T06:39:49.938780Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def preprocess_imgs(set_name, img_size):\n    \"\"\"\n    Resiza y aplica preprocesamiento VGG-15\n    \"\"\"\n    set_new = []\n    for img in set_name:\n        img = cv2.resize(\n            img,\n            dsize=img_size,\n            interpolation=cv2.INTER_CUBIC\n        )\n        set_new.append(preprocess_input(img))\n    return np.array(set_new)","metadata":{"papermill":{"duration":0.086662,"end_time":"2022-04-05T17:27:46.208822","exception":false,"start_time":"2022-04-05T17:27:46.12216","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:49.941989Z","iopub.execute_input":"2022-06-26T06:39:49.943631Z","iopub.status.idle":"2022-06-26T06:39:49.950565Z","shell.execute_reply.started":"2022-06-26T06:39:49.943588Z","shell.execute_reply":"2022-06-26T06:39:49.949650Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"X_train_prep = preprocess_imgs(set_name=X_train_crop, img_size=IMG_SIZE)\nX_test_prep = preprocess_imgs(set_name=X_test_crop, img_size=IMG_SIZE)\nX_val_prep = preprocess_imgs(set_name=X_val_crop, img_size=IMG_SIZE)","metadata":{"papermill":{"duration":0.451455,"end_time":"2022-04-05T17:27:46.736677","exception":false,"start_time":"2022-04-05T17:27:46.285222","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:49.952171Z","iopub.execute_input":"2022-06-26T06:39:49.952580Z","iopub.status.idle":"2022-06-26T06:39:50.165283Z","shell.execute_reply.started":"2022-06-26T06:39:49.952542Z","shell.execute_reply":"2022-06-26T06:39:50.164111Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"plot_samples(X_train_prep, y_train, labels, 30)","metadata":{"papermill":{"duration":2.971611,"end_time":"2022-04-05T17:27:49.786083","exception":false,"start_time":"2022-04-05T17:27:46.814472","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:50.166612Z","iopub.execute_input":"2022-06-26T06:39:50.166966Z","iopub.status.idle":"2022-06-26T06:39:52.809068Z","shell.execute_reply.started":"2022-06-26T06:39:50.166931Z","shell.execute_reply":"2022-06-26T06:39:52.808254Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = 'TRAIN_CROP/'\nVAL_DIR = 'VAL_CROP/'\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    brightness_range=[0.5, 1.5],\n    horizontal_flip=True,\n    vertical_flip=True,\n    preprocessing_function=preprocess_input\n)\n\ntest_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input\n)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_DIR,\n    color_mode='rgb',\n    target_size=IMG_SIZE,\n    batch_size=32,\n    class_mode='binary',\n    seed=RANDOM_SEED\n)\n\n\nvalidation_generator = test_datagen.flow_from_directory(\n    VAL_DIR,\n    color_mode='rgb',\n    target_size=IMG_SIZE,\n    batch_size=16,\n    class_mode='binary',\n    seed=RANDOM_SEED\n)","metadata":{"papermill":{"duration":0.326393,"end_time":"2022-04-05T17:27:50.220884","exception":false,"start_time":"2022-04-05T17:27:49.894491","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:52.810281Z","iopub.execute_input":"2022-06-26T06:39:52.811571Z","iopub.status.idle":"2022-06-26T06:39:53.030923Z","shell.execute_reply.started":"2022-06-26T06:39:52.811533Z","shell.execute_reply":"2022-06-26T06:39:53.029488Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# Cargamos el modelo Base\n\nbase_model = VGG16(\n     weights=\"imagenet\",\n     include_top=False, \n     input_shape=IMG_SIZE + (3,)\n)\n\nRMSprop(\n    learning_rate=0.001,\n    rho=0.9,\n    momentum=0.0,\n    epsilon=1e-07,\n    centered=False,\n    name=\"RMSprop\",\n)\n\"\"\"\n\nNUM_CLASSES = 1\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2048, activation='relu'))\nmodel.add(layers.Dense(1024, activation='relu'))\nmodel.add(layers.Dense(100, activation='relu'))\nmodel.add(layers.Dense(64,activation='relu'))\nmodel.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\nmodel.layers[0].trainable = False\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=Adam(learning_rate=1e-4),\n    #optimizer=RMSprop(learning_rate=1e-4),\n    #optimizer=gradient_descent_v2.SGD(learning_rate=1e-4),\n    metrics=['accuracy']\n)\nmodel.summary()\n\n","metadata":{"papermill":{"duration":2.057084,"end_time":"2022-04-05T17:27:52.383853","exception":false,"start_time":"2022-04-05T17:27:50.326769","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:53.032581Z","iopub.execute_input":"2022-06-26T06:39:53.032943Z","iopub.status.idle":"2022-06-26T06:39:53.140021Z","shell.execute_reply.started":"2022-06-26T06:39:53.032908Z","shell.execute_reply":"2022-06-26T06:39:53.139018Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 60\nbatch_size=32\nval_batch_size=16\nes = EarlyStopping(\n    monitor='accuracy', \n    mode='max',\n    patience=60,\n    restore_best_weights=True\n)\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(X_train)//batch_size,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=len(X_test)//val_batch_size,\n    callbacks=[es]\n)","metadata":{"papermill":{"duration":1309.798742,"end_time":"2022-04-05T17:49:42.289186","exception":false,"start_time":"2022-04-05T17:27:52.490444","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:39:53.141379Z","iopub.execute_input":"2022-06-26T06:39:53.141819Z","iopub.status.idle":"2022-06-26T06:42:41.258666Z","shell.execute_reply.started":"2022-06-26T06:39:53.141781Z","shell.execute_reply":"2022-06-26T06:42:41.257622Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n# plot model performance\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","metadata":{"papermill":{"duration":0.584765,"end_time":"2022-04-05T17:49:43.033129","exception":false,"start_time":"2022-04-05T17:49:42.448364","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:42:41.260286Z","iopub.execute_input":"2022-06-26T06:42:41.260656Z","iopub.status.idle":"2022-06-26T06:42:41.666474Z","shell.execute_reply.started":"2022-06-26T06:42:41.260619Z","shell.execute_reply":"2022-06-26T06:42:41.665538Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# validate on val set\npredictions = model.predict(X_val_prep)\npredictions = [1 if x>0.5 else 0 for x in predictions]\n\naccuracy = accuracy_score(y_val, predictions)\nprint('Val Accuracy = %.2f' % accuracy)\n\nconfusion_mtx = confusion_matrix(y_val, predictions) \ncm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n","metadata":{"papermill":{"duration":11.988554,"end_time":"2022-04-05T17:49:55.195839","exception":false,"start_time":"2022-04-05T17:49:43.207285","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:42:41.667691Z","iopub.execute_input":"2022-06-26T06:42:41.669596Z","iopub.status.idle":"2022-06-26T06:42:44.248274Z","shell.execute_reply.started":"2022-06-26T06:42:41.669557Z","shell.execute_reply":"2022-06-26T06:42:44.247385Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# validate on test set\npredictions = model.predict(X_test_prep)\npredictions = [1 if x>0.5 else 0 for x in predictions]\n\naccuracy = accuracy_score(y_test, predictions)\nprint('Test Accuracy = %.2f' % accuracy)\nconfusion_mtx = confusion_matrix(y_test, predictions) \ncm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)","metadata":{"papermill":{"duration":11.598191,"end_time":"2022-04-05T17:50:06.954843","exception":false,"start_time":"2022-04-05T17:49:55.356652","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:42:44.254383Z","iopub.execute_input":"2022-06-26T06:42:44.256598Z","iopub.status.idle":"2022-06-26T06:42:44.845960Z","shell.execute_reply.started":"2022-06-26T06:42:44.256559Z","shell.execute_reply":"2022-06-26T06:42:44.845028Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport zipfile\n# clean up the space\n!rm -rf TRAIN TEST VAL TRAIN_CROP TEST_CROP VAL_CROP\n# save the model\nmodel.save('2022-03-29_VGG16_model.h5')\n#Para salvar el modelo en formato protobuf\nVersion=\"202203290002\"\nmodel_path=os.getcwd()\nexport_path=os.path.join(model_path,Version)\ntf.saved_model.save(model,export_path)\nmodelZiped=zipfile.ZipFile(\"modelZiped.zip\",\"w\")\nfor folder, subfolders, files in os.walk(export_path):\n     for file in files:\n            modelZiped.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), ''), \n                             compress_type = zipfile.ZIP_DEFLATED)\nmodelZiped.close()\n","metadata":{"papermill":{"duration":30.157021,"end_time":"2022-04-05T17:50:37.278905","exception":false,"start_time":"2022-04-05T17:50:07.121884","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-26T06:42:44.850477Z","iopub.execute_input":"2022-06-26T06:42:44.852707Z","iopub.status.idle":"2022-06-26T06:43:24.822353Z","shell.execute_reply.started":"2022-06-26T06:42:44.852669Z","shell.execute_reply":"2022-06-26T06:43:24.821184Z"},"trusted":true},"execution_count":25,"outputs":[]}]}